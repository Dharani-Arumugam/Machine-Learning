{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Digit Recognition - SVM\n",
    "\n",
    "### Objective :\n",
    "\n",
    " - To explore the MNIST dataset and build an SVM classifier model to classify handwritten digits.\n",
    " - A classic problem in the field of pattern recognition is that of handwritten digit recognition. Suppose that you have images of handwritten digits ranging from 0-9 written by various people in boxes of a specific size - similar to the application forms in banks and universities.\n",
    " - The goal is to develop a model using Support Vector Maching that can correctly identify the digit (between 0-9) based on the pixel values given as features. Thus, it is a 10-class classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Description :\n",
    "- MNIST data which is a large database of handwritten digits.The 'pixel values' of each digit (image) comprise the features, and the actual number between 0-9 is the label.  \n",
    "- Since each image is of 28 x 28 pixels, and each pixel forms a feature, there are 784 features.\n",
    "\n",
    "### Note :\n",
    "- Since the training dataset is quite large (42,000 labelled images), it would take a lot of time for training an SVM on the full MNIST data, so it's better to sub-sample the data for training (10-20% of the data should be enough to achieve decent accuracy). Also, running a GridSearchCV() may take hours if you use a large value of k (fold-CV) such as 10 and a wide range of hyperparameters; k = 5 should be sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "5      0       0       0       0       0       0       0       0       0   \n",
       "6      7       0       0       0       0       0       0       0       0   \n",
       "7      3       0       0       0       0       0       0       0       0   \n",
       "8      5       0       0       0       0       0       0       0       0   \n",
       "9      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "5       0  ...         0         0         0         0         0         0   \n",
       "6       0  ...         0         0         0         0         0         0   \n",
       "7       0  ...         0         0         0         0         0         0   \n",
       "8       0  ...         0         0         0         0         0         0   \n",
       "9       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "5         0         0         0         0  \n",
       "6         0         0         0         0  \n",
       "7         0         0         0         0  \n",
       "8         0         0         0         0  \n",
       "9         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits = pd.read_csv('train.csv')\n",
    "digits.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row define a hand written digit stored in image of about 28 * 28 pixels combining to 784 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784,)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking one row to check \n",
    "three = digits.iloc[9, 1:]\n",
    "three.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1e1636a0d0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the array image\n",
    "three = three.values.reshape(28,28)\n",
    "plt.imshow(three, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  25 152 253 253 253 253 253 253 253 253 253 124   0   0   0   0   0]\n",
      " [  0 135 225 244 253 202 200 181 164 216 253 253 211 151   0   0   0   0]\n",
      " [  0   0  30 149  78   3   0   0   0  20 134 253 253 224   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  28 206 253 253 224   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  78 253 253 253 224   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   5  99 234 253 253 224   0   0   0   0]\n",
      " [  0   0   0   0   0   0  14 142 220 219 236 253 253 240 121   7   0   0]\n",
      " [  0   0   0   0   0   0  24 253 253 253 253 235 233 253 253 185  53   0]\n",
      " [  0   0   0   0   0   0   8 150 194 194 194  53  40  97 253 253 170   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0 122 253 253 170   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  55 237 253 253 170   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0 130 253 253 253 170   0]\n",
      " [  0   0   0   0   0   0   0   0   0   4  12 120 193 253 253 214  28   0]\n",
      " [  0   0   0   0   0   0   0   0   7 153 253 253 253 253 212  30   0   0]\n",
      " [  0  33 136  70   6   0  27  67 186 253 253 253 253 234  31   0   0   0]\n",
      " [ 26 231 253 253 191 183 223 253 253 253 253 172 216 112   0   0   0   0]\n",
      " [ 36 215 253 253 253 253 253 253 253 253 253  47  25   0   0   0   0   0]\n",
      " [  5  87 223 253 253 253 244 152 223 223 109   4   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "#visualize the array\n",
    "print(three[5:-5, 5:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarise the count of label to see how many labels of each digit is present \n",
    "digits.label.astype('category').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    11.1524\n",
       "7    10.4786\n",
       "3    10.3595\n",
       "9     9.9714\n",
       "2     9.9452\n",
       "6     9.8500\n",
       "0     9.8381\n",
       "4     9.6952\n",
       "8     9.6738\n",
       "5     9.0357\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarise the count in percentage \n",
    "round(digits.label.astype('category').value_counts()/len(digits.index)*100, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each digit has an approximate value of around 9-11% in the dataset and hence the dataset is balanced. Hence we can very well go ahead with SVM as our choice of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.00000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>42000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.456643</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.219286</td>\n",
       "      <td>0.117095</td>\n",
       "      <td>0.059024</td>\n",
       "      <td>0.02019</td>\n",
       "      <td>0.017238</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.887730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.312890</td>\n",
       "      <td>4.633819</td>\n",
       "      <td>3.274488</td>\n",
       "      <td>1.75987</td>\n",
       "      <td>1.894498</td>\n",
       "      <td>0.414264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>253.000000</td>\n",
       "      <td>253.00000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              label   pixel0   pixel1   pixel2   pixel3   pixel4   pixel5  \\\n",
       "count  42000.000000  42000.0  42000.0  42000.0  42000.0  42000.0  42000.0   \n",
       "mean       4.456643      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "std        2.887730      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "min        0.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "25%        2.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "50%        4.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "75%        7.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "max        9.000000      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "        pixel6   pixel7   pixel8  ...      pixel774      pixel775  \\\n",
       "count  42000.0  42000.0  42000.0  ...  42000.000000  42000.000000   \n",
       "mean       0.0      0.0      0.0  ...      0.219286      0.117095   \n",
       "std        0.0      0.0      0.0  ...      6.312890      4.633819   \n",
       "min        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "25%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "50%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "75%        0.0      0.0      0.0  ...      0.000000      0.000000   \n",
       "max        0.0      0.0      0.0  ...    254.000000    254.000000   \n",
       "\n",
       "           pixel776     pixel777      pixel778      pixel779  pixel780  \\\n",
       "count  42000.000000  42000.00000  42000.000000  42000.000000   42000.0   \n",
       "mean       0.059024      0.02019      0.017238      0.002857       0.0   \n",
       "std        3.274488      1.75987      1.894498      0.414264       0.0   \n",
       "min        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "25%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "50%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "75%        0.000000      0.00000      0.000000      0.000000       0.0   \n",
       "max      253.000000    253.00000    254.000000     62.000000       0.0   \n",
       "\n",
       "       pixel781  pixel782  pixel783  \n",
       "count   42000.0   42000.0   42000.0  \n",
       "mean        0.0       0.0       0.0  \n",
       "std         0.0       0.0       0.0  \n",
       "min         0.0       0.0       0.0  \n",
       "25%         0.0       0.0       0.0  \n",
       "50%         0.0       0.0       0.0  \n",
       "75%         0.0       0.0       0.0  \n",
       "max         0.0       0.0       0.0  \n",
       "\n",
       "[8 rows x 785 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#describe the dataset\n",
    "digits.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rescaling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import scale \n",
    "X = digits.drop('label', axis=1)\n",
    "y = digits['label'] \n",
    "\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.1, test_size=0.9, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Since the training dataset is quite large (42,000 labelled images), it would take a lot of time for training an SVM on the full MNIST data, it can be sub-sampled training (10-20% of the data should be enough to achieve decent accuracy).\n",
    "- Also, running a GridSearchCV() may take hours if we use large value of k (fold-CV) such as 10 and a wide range of hyperparameters; k = 5 should be sufficient.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 784)\n",
      "(37800,)\n",
      "(4200, 784)\n",
      "(4200,)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lets try building the linear model with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "linear_model = SVC(kernel='linear') \n",
    "\n",
    "linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction \n",
    "y_pred = linear_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3560,    0,   17,   15,   14,   41,   49,    8,   11,    2],\n",
       "       [   0, 4139,   25,   13,    2,   16,    5,   11,   25,    3],\n",
       "       [  50,   26, 3361,   76,   64,   11,   50,   39,   68,   10],\n",
       "       [  26,   24,  113, 3442,    8,  140,    8,   41,  101,   22],\n",
       "       [  13,   20,   28,    8, 3378,   11,   21,   13,   11,  155],\n",
       "       [  33,   35,   40,  196,   37, 2954,   59,    7,   63,   21],\n",
       "       [  49,   13,   51,    9,   34,   48, 3495,    0,    7,    0],\n",
       "       [   4,   38,   42,   34,   69,    4,    2, 3602,    7,  130],\n",
       "       [  33,   93,   95,  148,   28,  107,   36,   31, 3028,   46],\n",
       "       [  27,   18,   24,   58,  177,   21,    1,  175,   29, 3248]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Confusion matrix is showing 10 * 10 array, because, there are 10 classifications in the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9049470899470899"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score \n",
    "accuracy_score(y_true=y_test, y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overall accuracy of linear model is 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95      3717\n",
      "           1       0.94      0.98      0.96      4239\n",
      "           2       0.89      0.90      0.89      3755\n",
      "           3       0.86      0.88      0.87      3925\n",
      "           4       0.89      0.92      0.90      3658\n",
      "           5       0.88      0.86      0.87      3445\n",
      "           6       0.94      0.94      0.94      3706\n",
      "           7       0.92      0.92      0.92      3932\n",
      "           8       0.90      0.83      0.87      3645\n",
      "           9       0.89      0.86      0.88      3778\n",
      "\n",
      "    accuracy                           0.90     37800\n",
      "   macro avg       0.90      0.90      0.90     37800\n",
      "weighted avg       0.90      0.90      0.90     37800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check the class wise accuracy \n",
    "from sklearn.metrics import classification_report \n",
    "class_wise_report = classification_report(y_true=y_test, y_pred=y_pred)\n",
    "print(class_wise_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4846"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Linear SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a non-linear model with the RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rbf kernel with other hyperparameters kept to default \n",
    "\n",
    "svm_rbf = SVC(kernel='rbf')\n",
    "svm_rbf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9163227513227513\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "predictions = svm_rbf.predict(X_test)\n",
    "\n",
    "# accuracy \n",
    "print(accuracy_score(y_true=y_test, y_pred=predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy achieved with a non-linear kernel is slightly higher than a linear one. Let's now do a grid search CV to tune the hyperparameters C and gamma.\n",
    "\n",
    "### Grid Search Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 10, 100], 'gamma': [0.01, 0.001, 0.0001]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conduct (grid search) cross-validation to find the optimal values \n",
    "# of cost C and the choice of kernel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'C':[1, 10, 100], \n",
    "             'gamma': [1e-2, 1e-3, 1e-4]}\n",
    "\n",
    "# instantiate a model \n",
    "svc_grid_search = SVC(kernel=\"rbf\")\n",
    "\n",
    "# create a classifier to perform grid search\n",
    "clf = GridSearchCV(svc_grid_search, param_grid=parameters, scoring='accuracy')\n",
    "\n",
    "# fit\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19.451374</td>\n",
       "      <td>0.367787</td>\n",
       "      <td>3.188463</td>\n",
       "      <td>0.035424</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 1, 'gamma': 0.01}</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.682143</td>\n",
       "      <td>0.713095</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.891897</td>\n",
       "      <td>0.041040</td>\n",
       "      <td>1.934483</td>\n",
       "      <td>0.050763</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.001}</td>\n",
       "      <td>0.922619</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.901190</td>\n",
       "      <td>0.903571</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.917143</td>\n",
       "      <td>0.012769</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.955460</td>\n",
       "      <td>0.050329</td>\n",
       "      <td>2.701593</td>\n",
       "      <td>0.034979</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 1, 'gamma': 0.0001}</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.882857</td>\n",
       "      <td>0.006633</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19.806081</td>\n",
       "      <td>0.223667</td>\n",
       "      <td>3.305326</td>\n",
       "      <td>0.193981</td>\n",
       "      <td>10</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 10, 'gamma': 0.01}</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.729762</td>\n",
       "      <td>0.739286</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.002402</td>\n",
       "      <td>0.050179</td>\n",
       "      <td>1.660530</td>\n",
       "      <td>0.035143</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.001}</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.939286</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.915476</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.926190</td>\n",
       "      <td>0.013084</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.040841</td>\n",
       "      <td>0.041570</td>\n",
       "      <td>1.528343</td>\n",
       "      <td>0.031380</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 10, 'gamma': 0.0001}</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.932143</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.908333</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.011344</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>19.645269</td>\n",
       "      <td>0.056375</td>\n",
       "      <td>3.194759</td>\n",
       "      <td>0.024039</td>\n",
       "      <td>100</td>\n",
       "      <td>0.01</td>\n",
       "      <td>{'C': 100, 'gamma': 0.01}</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.729762</td>\n",
       "      <td>0.739286</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>0.734762</td>\n",
       "      <td>0.015529</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.172896</td>\n",
       "      <td>0.266861</td>\n",
       "      <td>1.744798</td>\n",
       "      <td>0.101970</td>\n",
       "      <td>100</td>\n",
       "      <td>0.001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.001}</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.907143</td>\n",
       "      <td>0.917857</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.927143</td>\n",
       "      <td>0.012585</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3.615347</td>\n",
       "      <td>0.548068</td>\n",
       "      <td>1.665609</td>\n",
       "      <td>0.149114</td>\n",
       "      <td>100</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'C': 100, 'gamma': 0.0001}</td>\n",
       "      <td>0.920238</td>\n",
       "      <td>0.927381</td>\n",
       "      <td>0.901190</td>\n",
       "      <td>0.905952</td>\n",
       "      <td>0.925000</td>\n",
       "      <td>0.915952</td>\n",
       "      <td>0.010476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0      19.451374      0.367787         3.188463        0.035424       1   \n",
       "1       5.891897      0.041040         1.934483        0.050763       1   \n",
       "2       8.955460      0.050329         2.701593        0.034979       1   \n",
       "3      19.806081      0.223667         3.305326        0.193981      10   \n",
       "4       5.002402      0.050179         1.660530        0.035143      10   \n",
       "5       4.040841      0.041570         1.528343        0.031380      10   \n",
       "6      19.645269      0.056375         3.194759        0.024039     100   \n",
       "7       5.172896      0.266861         1.744798        0.101970     100   \n",
       "8       3.615347      0.548068         1.665609        0.149114     100   \n",
       "\n",
       "  param_gamma                       params  split0_test_score  \\\n",
       "0        0.01      {'C': 1, 'gamma': 0.01}           0.725000   \n",
       "1       0.001     {'C': 1, 'gamma': 0.001}           0.922619   \n",
       "2      0.0001    {'C': 1, 'gamma': 0.0001}           0.880952   \n",
       "3        0.01     {'C': 10, 'gamma': 0.01}           0.747619   \n",
       "4       0.001    {'C': 10, 'gamma': 0.001}           0.935714   \n",
       "5      0.0001   {'C': 10, 'gamma': 0.0001}           0.919048   \n",
       "6        0.01    {'C': 100, 'gamma': 0.01}           0.747619   \n",
       "7       0.001   {'C': 100, 'gamma': 0.001}           0.934524   \n",
       "8      0.0001  {'C': 100, 'gamma': 0.0001}           0.920238   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.726190           0.708333           0.723810           0.682143   \n",
       "1           0.934524           0.901190           0.903571           0.923810   \n",
       "2           0.895238           0.876190           0.878571           0.883333   \n",
       "3           0.750000           0.729762           0.739286           0.707143   \n",
       "4           0.939286           0.905952           0.915476           0.934524   \n",
       "5           0.932143           0.900000           0.908333           0.923810   \n",
       "6           0.750000           0.729762           0.739286           0.707143   \n",
       "7           0.940476           0.907143           0.917857           0.935714   \n",
       "8           0.927381           0.901190           0.905952           0.925000   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.713095        0.016785                9  \n",
       "1         0.917143        0.012769                3  \n",
       "2         0.882857        0.006633                6  \n",
       "3         0.734762        0.015529                7  \n",
       "4         0.926190        0.013084                2  \n",
       "5         0.916667        0.011344                4  \n",
       "6         0.734762        0.015529                7  \n",
       "7         0.927143        0.012585                1  \n",
       "8         0.915952        0.010476                5  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# results\n",
    "cv_results = pd.DataFrame(clf.cv_results_)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mean_train_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-0e620776d439>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"param_C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_test_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"param_C\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mean_train_score\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'mean_train_score'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# converting C to numeric type for plotting on x-axis\n",
    "cv_results['param_C'] = cv_results['param_C'].astype('int')\n",
    "\n",
    "# # plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "\n",
    "# subplot 1/3\n",
    "plt.subplot(131)\n",
    "gamma_01 = cv_results[cv_results['param_gamma']==0.01]\n",
    "\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_test_score\"])\n",
    "plt.plot(gamma_01[\"param_C\"], gamma_01[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.01\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "# subplot 2/3\n",
    "plt.subplot(132)\n",
    "gamma_001 = cv_results[cv_results['param_gamma']==0.001]\n",
    "\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_test_score\"])\n",
    "plt.plot(gamma_001[\"param_C\"], gamma_001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "\n",
    "# subplot 3/3\n",
    "plt.subplot(133)\n",
    "gamma_0001 = cv_results[cv_results['param_gamma']==0.0001]\n",
    "\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_test_score\"])\n",
    "plt.plot(gamma_0001[\"param_C\"], gamma_0001[\"mean_train_score\"])\n",
    "plt.xlabel('C')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title(\"Gamma=0.0001\")\n",
    "plt.ylim([0.60, 1])\n",
    "plt.legend(['test accuracy', 'train accuracy'], loc='lower right')\n",
    "plt.xscale('log')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plot above, we can observe that (from higher to lower gamma / left to right):\n",
    "- At very high gamma (0.01), the model is achieving 100% accuracy on the training data, though the test score is quite low (<75%). Thus, the model is overfitting.\n",
    "\n",
    "- At gamma=0.001, the training and test scores are comparable at around C=1, though the model starts to overfit at higher values of C\n",
    "\n",
    "- At gamma=0.0001, the model does not overfit till C=10 but starts showing signs at C=100. Also, the training and test scores are slightly lower than at gamma=0.001.\n",
    "\n",
    "Thus, it seems that the best combination is gamma=0.001 and C=1 (the plot in the middle), which gives the highest test accuracy (~92%) while avoiding overfitting.\n",
    "\n",
    "Let's now build the final model and see the performance on test data.\n",
    "\n",
    "### Final Model\n",
    "\n",
    "Let's now build the final model with chosen hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal hyperparameters\n",
    "best_C = 1\n",
    "best_gamma = 0.001\n",
    "\n",
    "# model\n",
    "svm_final = SVC(kernel='rbf', C=best_C, gamma=best_gamma)\n",
    "\n",
    "# fit\n",
    "svm_final.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "predictions = svm_final.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation: CM \n",
    "confusion = metrics.confusion_matrix(y_true = y_test, y_pred = predictions)\n",
    "\n",
    "# measure accuracy\n",
    "test_accuracy = metrics.accuracy_score(y_true=y_test, y_pred=predictions)\n",
    "\n",
    "print(test_accuracy, \"\\n\")\n",
    "print(confusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "The final accuracy on test data is approx. 92%. Note that this can be significantly increased by using the entire training data of 42,000 images (we have used just 10% of that!). \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
